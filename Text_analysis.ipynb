{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7ME-ag0hoDA"
   },
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import nltk\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "import fasttext\n",
    "import pymorphy2\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/86/ff826211bc9e28d4c371668b30b4b2c38a09127e5e73017b1c0cd52f9dfa/fasttext-0.8.3.tar.gz (73kB)\n",
      "Requirement already satisfied: numpy>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from fasttext) (1.16.1)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from fasttext) (0.17.1)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py): started\n",
      "  Building wheel for fasttext (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Bagi\\AppData\\Local\\pip\\Cache\\wheels\\73\\8e\\5d\\ecb50b90adaab5868ae1d8df180f31e55e85c2f055aaf2fb35\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "Successfully installed fasttext-0.8.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\programdata\\anaconda3\\lib\\site-packages (0.8)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.393442.3710985)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3\n",
      "  Downloading https://files.pythonhosted.org/packages/00/8c/98b43c5822620458704e187a1666616c1e21a846ede8ffda493aabe11207/pymystem3-0.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from pymystem3) (2.21.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pymystem3) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pymystem3) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pymystem3) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pymystem3) (3.0.4)\n",
      "Installing collected packages: pymystem3\n",
      "Successfully installed pymystem3-0.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "qxZMU8CBK664",
    "outputId": "ad5442ea-27c3-4357-8ab9-6249143c49ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Начальник Главного оперативного управления Ген...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Артиллерийские подразделения общевойскового об...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Подразделения морской пехоты Каспийской флотил...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Команды на всеармейских этапах конкурсов АрМИ-...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>На большом учебно-методическом командирском сб...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text source\n",
       "0  Начальник Главного оперативного управления Ген...    mil\n",
       "1  Артиллерийские подразделения общевойскового об...    mil\n",
       "2  Подразделения морской пехоты Каспийской флотил...    mil\n",
       "3  Команды на всеармейских этапах конкурсов АрМИ-...    mil\n",
       "4  На большом учебно-методическом командирском сб...    mil"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('vk_texts_with_sources.csv', usecols = ['text', 'source'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYNCAr17MFA3"
   },
   "source": [
    "# Домашнее задание\n",
    "\n",
    "В этом домашнем задании вы будете решать задачу тематической классификации. Даны тексты, опубликованные в нескольких пабликах VK.com, посвященных государственным и муниципальным службам. Формально задача заключается в том, чтобы по тексту ($d$) определить в каком паблике он опубликован, то есть, к какому классу $c$ он принадлежит. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2EnN-U7MemU"
   },
   "source": [
    "## Задание 1 [1 балл]. Описательные статистики\n",
    "Посчитайте:\n",
    "* количество текстов и количество классов\n",
    "* количество слов (без лемматизации и с лемматизацией) в коллекции\n",
    "* среднюю длину текста в словах и символах\n",
    "* найдите 5 самых частых существительных в текстах каждого паблика \n",
    "\n",
    "*Рекомендуем использовать pandas для расчета описательных статистик.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTJPlulvQSqQ"
   },
   "source": [
    "Разделите коллекцию текстов на обучающую и тестовую части. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего текстов : 11625\n",
      "Пустые тексты : 99\n",
      "Уникальные тексты : 11149\n"
     ]
    }
   ],
   "source": [
    "print('Всего текстов :', df.shape[0])\n",
    "print('Пустые тексты :', df['text'].isna().sum())\n",
    "print('Уникальные тексты :', df['text'].nunique())\n",
    "#убираем пустые и с дубликатами\n",
    "df = df.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего классов: 4\n"
     ]
    }
   ],
   "source": [
    "print('Всего классов:', df['source'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество слов (без лемматизации) в коллекции: 96746\n"
     ]
    }
   ],
   "source": [
    "words_bag = set()\n",
    "df['text'].apply(lambda text: words_bag.update(set(nltk.tokenize.word_tokenize(text))))    \n",
    "print('Количество слов (без лемматизации) в коллекции:', len(words_bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem(mystem_bin='C://Users/Bagi/MachineLearning/mystem.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество слов (c лемматизацией) в коллекции: 31489\n"
     ]
    }
   ],
   "source": [
    "lemmatize_words_bag = set()\n",
    "for word in words_bag:\n",
    "lemmatize_words_bag.add(m.lemmatize(word)[0])\n",
    "print('Количество слов (c лемматизацией) в коллекции:', len(lemmatize_words_bag))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя длина текста в словах: 122.69765982246929\n",
      "Средняя длина текста в символах: 711.1856899488927\n"
     ]
    }
   ],
   "source": [
    "print('Средняя длина текста в словах:', np.mean([len(nltk.tokenize.word_tokenize(text)) for text in df['text']]))\n",
    "print('Средняя длина текста в символах:', np.mean([len(text) for text in df['text']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ 5 самых частых слов mil : минобороны, военный, россия, год, оборона\n",
      "Топ 5 самых частых слов mchsgov : мчс, мчсроссия, россия, спасатель, человек\n",
      "Топ 5 самых частых слов russianpost : почта, россия, год, отделение, письмо\n",
      "Топ 5 самых частых слов mospolice : полиция, мвд, москва, россия, сотрудник\n"
     ]
    }
   ],
   "source": [
    "morph_analyzer = pymorphy2.MorphAnalyzer()\n",
    "for source in df['source'].unique():\n",
    "    counter = collections.Counter()\n",
    "    for text in df[df['source'] == source]['text']:\n",
    "        for word in nltk.tokenize.word_tokenize(text): \n",
    "            parsed = morph_analyzer.parse(word)[0]\n",
    "            if 'NOUN' in parsed.tag:\n",
    "                counter.update([parsed.normal_form])\n",
    "    print('Топ 5 самых частых слов', source, ':', ', '.join([word[0] for word in counter.most_common(5)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#предобработка текста, оставляем слова из символов русского и латинского алфавитов\n",
    "def text_transform(text: pd.Series) -> pd.Series:\n",
    "    return text.str.lower().replace(\"[^а-яА-Яa-zA-Z0-9]\", \" \", regex=True)\n",
    "def lemmatize(text, mystem=m):\n",
    "    return \"\".join(m.lemmatize(text)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df.copy()\n",
    "df_transformed.text = df.apply(text_transform)\n",
    "df_transformed.text  = df_transformed.text.apply(lemmatize)\n",
    "X = df_transformed.drop('source', axis=1)\n",
    "y = df_transformed['source']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9yCVYfbpNhXd"
   },
   "source": [
    " ## Задание 2 [2 балла]. Классификация по правилам\n",
    " \n",
    " * Разработайте несколько правил вида \"Если встречается слово $w$, то текст относится к паблику $c$\"\n",
    " * Посчитайте, какую точность, полноту, $f$-меру и $accuracy$ вы получаете при классификации по правилам\n",
    " * Получилось ли у вас придумать правило, которое никогда не ошибается?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22tJKQnaOjie"
   },
   "source": [
    "## Задание 3 [3 балла]. Baseline\n",
    "Используйте стандартный ```sklearn.pipeline``` для классификации текстов: \n",
    "* векторизация \n",
    "* $tf-idf$ взвешивание \n",
    "* ваш любимый метод классификации.\n",
    "\n",
    "\n",
    "Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('tfidf', TfidfVectorizer(ngram_range = (1, 2), max_df=0.95)), ('lgb', LGBMClassifier())])\n",
    "pipe.fit(X_train['text'], y_train)\n",
    "y_pred = pipe.predict(X_test['text'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.9731086410899964\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     mchsgov       0.97      0.96      0.97       705\n",
      "         mil       0.99      0.98      0.98       741\n",
      "   mospolice       0.98      0.98      0.98       711\n",
      " russianpost       0.96      0.96      0.96       632\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2789\n",
      "   macro avg       0.97      0.97      0.97      2789\n",
      "weighted avg       0.97      0.97      0.97      2789\n",
      "\n",
      "confusion_matrix:\n",
      " [[680   6   0  19]\n",
      " [ 12 729   0   0]\n",
      " [  2   1 699   9]\n",
      " [  9   4  13 606]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(y_test, y_pred))\n",
    "print('classification_report:\\n', classification_report(y_test, y_pred))\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "показатели качества достаточно высоки, алгоритм не только почти во всех случаях правильно отгадывает класс, но и редко присваивает неправильный класс не тому тексту.\n",
    "например, тексты 3 класса только 13 раз были обозначены как 4 класса, т.е с 1 и 2 классами они хорошо разделимы. Также тексты 4 темы, не были ни разу обозначены 2 темой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4m1rDQ3PAqO"
   },
   "source": [
    "## Задание 4 [2 балла]. Снижение размерности\n",
    "Добавьте в ваш ```sklearn.pipeline```  методы снижения размерности:  PCA / LSI / LSA / LDA / другое. Какие методы классификации разумно использовать после снижения размерности? Как изменились результаты классификации после добавления нового шага?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('tfidf', TfidfVectorizer(ngram_range = (1, 2), max_df=0.95)),\n",
    "                 ('lsa', TruncatedSVD(n_components=6)),\n",
    "                 ('lgb', LGBMClassifier())])\n",
    "pipe.fit(X_train['text'], y_train)\n",
    "y_pred = pipe.predict(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.951954105414127\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     mchsgov       0.94      0.91      0.93       705\n",
      "         mil       0.96      0.97      0.96       741\n",
      "   mospolice       0.97      0.99      0.98       711\n",
      " russianpost       0.93      0.94      0.94       632\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2789\n",
      "   macro avg       0.95      0.95      0.95      2789\n",
      "weighted avg       0.95      0.95      0.95      2789\n",
      "\n",
      "confusion_matrix:\n",
      " [[641  26   4  34]\n",
      " [ 20 718   0   3]\n",
      " [  3   1 702   5]\n",
      " [ 15   5  18 594]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(y_test, y_pred))\n",
    "print('classification_report:\\n', classification_report(y_test, y_pred))\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После методов снижения размерности следует использовать алгоритмы требовательные к памяти и долгие по времени обучения, т.к количество признаков уменьшится и данные параметры также сократятся\n",
    "алгоритмы, не допускающие корреляции признаков\n",
    "Результаты классификации показывают снижение качества, алгоритм стал больше ошибаться и относить объект к неправильному классу. Тяжелее оценить, какие темы лучше разделимы, но видно что количество неправильно отнесенных к 1 классу объектов 4 выросло почти в 2 раза, тогда как объекты 2 класса неправильно отнесенные к 1 почти в 5 раз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7vVPaaVwPVwg"
   },
   "source": [
    "## Задание 5 [1 балл]. Лемматизация\n",
    "Посмотрите, как влияет лемматизация на качество классификации. Как изменится качество классификации, если вы используете ```CountVectorizer``` на словах или $n$-граммах на лемматизированных текстах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('tfidf', CountVectorizer(ngram_range = (1, 2))),\n",
    "                 ('lsa', TruncatedSVD(n_components=6)),\n",
    "                 ('lgb', LGBMClassifier())])\n",
    "pipe.fit(X_train['text'], y_train)\n",
    "y_pred = pipe.predict(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.9268555037647902\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     mchsgov       0.89      0.88      0.89       705\n",
      "         mil       0.95      0.96      0.95       741\n",
      "   mospolice       0.97      0.98      0.97       711\n",
      " russianpost       0.90      0.88      0.89       632\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      2789\n",
      "   macro avg       0.93      0.93      0.93      2789\n",
      "weighted avg       0.93      0.93      0.93      2789\n",
      "\n",
      "confusion_matrix:\n",
      " [[622  24   6  53]\n",
      " [ 21 710   1   9]\n",
      " [  9   5 694   3]\n",
      " [ 48  11  14 559]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(y_test, y_pred))\n",
    "print('classification_report:\\n', classification_report(y_test, y_pred))\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('tfidf', CountVectorizer(dtype = np.float64, ngram_range = (1, 2))),\n",
    "                 ('lgb', LGBMClassifier())])\n",
    "pipe.fit(X_train['text'], y_train)\n",
    "y_pred = pipe.predict(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.9741842954463965\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     mchsgov       0.98      0.96      0.97       705\n",
      "         mil       0.98      0.99      0.99       741\n",
      "   mospolice       0.98      0.98      0.98       711\n",
      " russianpost       0.95      0.97      0.96       632\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2789\n",
      "   macro avg       0.97      0.97      0.97      2789\n",
      "weighted avg       0.97      0.97      0.97      2789\n",
      "\n",
      "confusion_matrix:\n",
      " [[679   7   0  19]\n",
      " [  9 731   0   1]\n",
      " [  3   1 696  11]\n",
      " [  4   4  13 611]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(y_test, y_pred))\n",
    "print('classification_report:\\n', classification_report(y_test, y_pred))\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество резко снизилось, если использовать понижение размерности и countvectorizer на нграммах и стало максимальным без него"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cdakRHahQp-l"
   },
   "source": [
    "## Задание 6 [3 балла]. Continious bag of words\n",
    "Для baseline решения мы использовали обычное представление текста в виде мешка слов. Попробуйте использовать другие модели представления текста – например, в виде непрерывного мешка слов, то есть, в виде набора эмбеддингов. Для того, чтобы получить вектор текста попробуйте:\n",
    "* усреднить все эмбеддинги слов, входящих в этот текст\n",
    "* усреднить все эмбеддинги слов, входящих в этот текст с $tf-idf$ весами\n",
    "* использовать любую модель эмбеддинга документа.\n",
    "\n",
    "Используйте любую модель эмбеддингов по вашему вкусу. \n",
    "\n",
    "\n",
    "Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [pd.concat([X_train, X_test])['text'].iloc[i].split() for i in range(len(df))]\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(texts)]\n",
    "doc2d = Doc2Vec(documents, vector_size=100, window=5, min_count=5, workers=4)\n",
    "train_doc = []\n",
    "for text in texts[:X_train.shape[0]]:\n",
    "    train_doc.append(model.infer_vector(texts[0]))\n",
    "test_doc = []\n",
    "for text in texts[X_train.shape[0]:]:\n",
    "    test_doc.append(model.infer_vector(texts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('lgb', LGBMClassifier())])\n",
    "pipe.fit(train_doc, y_train)\n",
    "y_pred = pipe.predict(test_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.25170311939763357\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     mchsgov       0.26      0.24      0.25       705\n",
      "         mil       0.26      0.34      0.29       741\n",
      "   mospolice       0.27      0.26      0.26       711\n",
      " russianpost       0.20      0.15      0.17       632\n",
      "\n",
      "   micro avg       0.25      0.25      0.25      2789\n",
      "   macro avg       0.25      0.25      0.25      2789\n",
      "weighted avg       0.25      0.25      0.25      2789\n",
      "\n",
      "confusion_matrix:\n",
      " [[172 227 176 130]\n",
      " [186 250 181 124]\n",
      " [154 258 186 113]\n",
      " [153 232 153  94]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(y_test, y_pred))\n",
    "print('classification_report:\\n', classification_report(y_test, y_pred))\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2vec проявил себя не лучшим образом, малая точность и полнота, выбирая наугад 1 из 4 классов, качество будет похожим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='\\\\b\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2v = Word2Vec(texts, size=100, window=5, min_count=5, workers=4)\n",
    "tf = TfidfVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "tf.fit(X_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(data, tfidf=None):\n",
    "    emb = []\n",
    "    for text in data['text']:\n",
    "        text_emb = []\n",
    "        for word in text:\n",
    "            try:\n",
    "                if tfidf is None:\n",
    "                    text_emb.append(word2v.wv.get_vector(word))\n",
    "                else:\n",
    "                    text_emb.append(word2v.wv.get_vector(word) * tfidf.vocabulary_[word])\n",
    "            except KeyError:\n",
    "                pass\n",
    "        emb.append(np.mean(text_emb, axis=0))\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word = get_text(X_train)\n",
    "test_word = get_text(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('lgb', LGBMClassifier())])\n",
    "pipe.fit(train_word, y_train)\n",
    "y_pred = pipe.predict(test_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.7970598780925062\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     mchsgov       0.86      0.78      0.82       705\n",
      "         mil       0.81      0.86      0.83       741\n",
      "   mospolice       0.81      0.82      0.81       711\n",
      " russianpost       0.70      0.72      0.71       632\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      2789\n",
      "   macro avg       0.80      0.79      0.79      2789\n",
      "weighted avg       0.80      0.80      0.80      2789\n",
      "\n",
      "confusion_matrix:\n",
      " [[551  31  37  86]\n",
      " [ 27 637  36  41]\n",
      " [ 22  44 582  63]\n",
      " [ 40  75  64 453]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(y_test, y_pred))\n",
    "print('classification_report:\\n', classification_report(y_test, y_pred))\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_tdf = get_text(X_train, tfidf=tf)\n",
    "test_word_tdf = get_text(X_test, tfidf=tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('lgb', LGBMClassifier())])\n",
    "pipe.fit(train_word_tdf, y_train)\n",
    "y_pred = pipe.predict(test_word_tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.7845105772678379\n",
      "classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     mchsgov       0.84      0.79      0.81       705\n",
      "         mil       0.78      0.81      0.79       741\n",
      "   mospolice       0.79      0.81      0.80       711\n",
      " russianpost       0.73      0.72      0.73       632\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      2789\n",
      "   macro avg       0.78      0.78      0.78      2789\n",
      "weighted avg       0.79      0.78      0.78      2789\n",
      "\n",
      "confusion_matrix:\n",
      " [[554  35  37  79]\n",
      " [ 29 601  69  42]\n",
      " [ 20  68 579  44]\n",
      " [ 59  69  50 454]]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(y_test, y_pred))\n",
    "print('classification_report:\\n', classification_report(y_test, y_pred))\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ситуация с Word2vec выглядит намного более оптимистичной, предсказание на основании близлежащих слов и одновременно этого набора слов на основании одного\n",
    "Из матрицы ошибок так же видно, что 4 тема оказалась менее доступной для алгоритма, ее больше всего он путал с другими темами, больше всего с первой.\n",
    "В связке с tfidf vectorizer качество несильно уменьшилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyVQ5Gm7Qzcz"
   },
   "source": [
    "## Задание 7 [2 балла]. fastText\n",
    "\n",
    "Используйте ```fastText``` в режиме классификации. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for idx, text in enumerate(X_train['text']):\n",
    "    rows.append(text + ' __label__' + y_train.iloc[idx])\n",
    "np.savetxt('data.train.txt', rows, fmt='%s', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь происходит что-то странное с кодировкой, файл model.bin создается не в той кодировке, а bin.vec отсутствует в принципе, по итогу ни одного предсказания. Данную штуку пофиксить не удалось("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ...]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = fasttext.supervised('data.train.txt', 'model', encoding='utf-8')\n",
    "#y_pred = [cls[0] for cls in classifier.predict(X_test['text'])]\n",
    "#for cls in classifier.predict(X_test['text']):\n",
    "#    print(cls[0])\n",
    "classifier.predict(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy_score:', accuracy_score(y_test, y_pred))\n",
    "print('classification_report:\\n', classification_report(y_test, y_pred))\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 8 [4 балла]. CNN\n",
    "\n",
    "Реализуйте модель Kim et al (2014) для решения задачи классификации с помощью CNN. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix).\n",
    "Ссылка: Kim Y. Convolutional Neural Networks for Sentence Classification. 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "emb_size = 100\n",
    "sequence_length = 50\n",
    "\n",
    "\n",
    "def build_model(w2v_model):\n",
    "    model_input = Input(shape=(sequence_length,))\n",
    "    x = Embedding(len(w2v_model.wv.vocab), emb_size, input_length=sequence_length, name=\"embedding\")(model_input)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    conv_blocks = []\n",
    "    for sz in [3, 7]:\n",
    "        conv = Convolution1D(filters=10, kernel_size=sz,  padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
    "        conv = MaxPooling1D()(conv)\n",
    "        conv = Flatten()(conv)\n",
    "        conv_blocks.append(conv)\n",
    "\n",
    "    x = Concatenate()(conv_blocks)\n",
    "\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    model_output = Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(model_input, model_output)\n",
    "    \n",
    "    # Initialize weights with word2vec\n",
    "    weights = np.array([w2v_model.wv.get_vector(word) for word in w2v_model.wv.vocab.keys()])\n",
    "    embedding_layer = model.get_layer(\"embedding\")\n",
    "    embedding_layer.set_weights([weights])\n",
    "    return model\n",
    "\n",
    "\n",
    "w2v_model = Word2Vec(texts, size=emb_size, window=5, min_count=1, workers=4)\n",
    "model = build_model(w2v_model)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {key:idx for idx, key in enumerate(word2v.wv.vocab.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences([[word_to_idx[word] for word in text.split()] for text in X_train['text']], \n",
    "                                   maxlen=sequence_length, padding=\"post\", truncating=\"post\")\n",
    "x_test = sequence.pad_sequences([[word_to_idx[word] for word in text.split()] for text in X_test['text']], \n",
    "                                  maxlen=sequence_length, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'mil': 0, 'mchsgov': 1, 'russianpost': 2, 'mospolice': 3}\n",
    "inv_labels = {0: 'mil', 1: 'mchsgov', 2: 'russianpost', 3: 'mospolice'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8364 samples, validate on 2789 samples\n",
      "Epoch 1/10\n",
      " - 10s - loss: 0.8681 - acc: 0.8754 - val_loss: 0.2627 - val_acc: 0.9165\n",
      "Epoch 2/10\n",
      " - 9s - loss: 0.1446 - acc: 0.9585 - val_loss: 0.1746 - val_acc: 0.9520\n",
      "Epoch 3/10\n",
      " - 9s - loss: 0.1047 - acc: 0.9694 - val_loss: 0.1513 - val_acc: 0.9624\n",
      "Epoch 4/10\n",
      " - 9s - loss: 0.0780 - acc: 0.9766 - val_loss: 0.1447 - val_acc: 0.9602\n",
      "Epoch 5/10\n",
      " - 9s - loss: 0.0627 - acc: 0.9825 - val_loss: 0.1615 - val_acc: 0.9588\n",
      "Epoch 6/10\n",
      " - 9s - loss: 0.0518 - acc: 0.9831 - val_loss: 0.1533 - val_acc: 0.9616\n",
      "Epoch 7/10\n",
      " - 9s - loss: 0.0468 - acc: 0.9849 - val_loss: 0.1605 - val_acc: 0.9620\n",
      "Epoch 8/10\n",
      " - 9s - loss: 0.0383 - acc: 0.9891 - val_loss: 0.2355 - val_acc: 0.9175\n",
      "Epoch 9/10\n",
      " - 9s - loss: 0.0348 - acc: 0.9904 - val_loss: 0.1517 - val_acc: 0.9634\n",
      "Epoch 10/10\n",
      " - 9s - loss: 0.0302 - acc: 0.9903 - val_loss: 0.1501 - val_acc: 0.9613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a52a1fd68>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, to_categorical([labels[y] for y in y_train], num_classes=4),\n",
    "          validation_data=(x_test, to_categorical([labels[y] for y in y_test], num_classes=4),),\n",
    "          batch_size=batch_size, epochs=num_epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сетка быстро обучалась, сильно наращивая за первые шаги все метрики качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 9 [4 + 2 балла]. RNN\n",
    "\n",
    "(4 балла)Используйте ```RNN``` (BLSTM с какими-то признаками и пулинг поверх) для решения задачи текстовой классификации. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix).\n",
    "\n",
    "За дополнительные 2 балла добавьте в модель символьные признаки - CharCNN или CharRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 50, 100)           3550500   \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 50, 128)           84480     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_55 (Flatten)         (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4)                 12804     \n",
      "=================================================================\n",
      "Total params: 3,647,784\n",
      "Trainable params: 3,647,784\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, TimeDistributed, Dropout, Bidirectional, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "word2v = Word2Vec(texts, size=emb_size, window=5, min_count=1, workers=4)\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "emb_size = 100\n",
    "sequence_length = 50\n",
    "\n",
    "def build_model(word2v):\n",
    "    weights = np.array([word2v.wv.get_vector(word) for word in word2v.wv.vocab.keys()])\n",
    "    model_input_sent = Input(shape=(sequence_length,))\n",
    "    x = Embedding(len(word2v.wv.vocab), emb_size, \n",
    "                  input_length=sequence_length, weights=[weights], \n",
    "                  name=\"embedding\")(model_input_sent)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=[model_input_sent], outputs=x)\n",
    "    return model\n",
    "model2 = build_model(word2v)\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"Adagrad\", metrics=[\"accuracy\"])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8364 samples, validate on 2789 samples\n",
      "Epoch 1/10\n",
      " - 12s - loss: 0.2803 - acc: 0.9183 - val_loss: 0.1393 - val_acc: 0.9688\n",
      "Epoch 2/10\n",
      " - 9s - loss: 0.1194 - acc: 0.9684 - val_loss: 0.1546 - val_acc: 0.9584\n",
      "Epoch 3/10\n",
      " - 9s - loss: 0.0896 - acc: 0.9754 - val_loss: 0.1212 - val_acc: 0.9674\n",
      "Epoch 4/10\n",
      " - 9s - loss: 0.0715 - acc: 0.9810 - val_loss: 0.1194 - val_acc: 0.9692\n",
      "Epoch 5/10\n",
      " - 9s - loss: 0.0593 - acc: 0.9839 - val_loss: 0.1261 - val_acc: 0.9688\n",
      "Epoch 6/10\n",
      " - 9s - loss: 0.0483 - acc: 0.9864 - val_loss: 0.1836 - val_acc: 0.9297\n",
      "Epoch 7/10\n",
      " - 9s - loss: 0.0413 - acc: 0.9889 - val_loss: 0.1177 - val_acc: 0.9738\n",
      "Epoch 8/10\n",
      " - 9s - loss: 0.0348 - acc: 0.9901 - val_loss: 0.1284 - val_acc: 0.9720\n",
      "Epoch 9/10\n",
      " - 9s - loss: 0.0298 - acc: 0.9912 - val_loss: 0.1184 - val_acc: 0.9699\n",
      "Epoch 10/10\n",
      " - 9s - loss: 0.0261 - acc: 0.9921 - val_loss: 0.1260 - val_acc: 0.9731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a99f52160>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, to_categorical([labels[y] for y in y_train], num_classes=4),\n",
    "          validation_data=(x_test, to_categorical([labels[y] for y in y_test], num_classes=4)),\n",
    "          batch_size=batch_size, epochs=num_epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реккурентная сеть так же стремительно уменьшала свою ошибку и растила качество\n",
    "Данный алгоритм не уступает предыдущему "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 10 [8 баллов]. ULMFit\n",
    "\n",
    "Используйте ```ULMFit``` для решения задачи классификации. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8fKqCD6Q5tW"
   },
   "source": [
    "## Конец\n",
    "Выполните какие-то из предыдущих заданий. Для всех заданий, кроме задания 1 требуется вычислить метрику accuracy метода.\n",
    "\n",
    "Подведите итоги и проведите сравнение всех использованных методов. Какой из них показался вам лучше и почему?\n",
    "\n",
    "**NB!** Задание обязательное вне зависимости от того, сколько из предыдущих пунктов вы выполнили, и дополнительных баллов не дает.\n",
    "\n",
    "\n",
    "Для получения полной оценки за NLP-часть достаточно набрать **20 баллов**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4FkOuR_NiXeT"
   },
   "source": [
    "# Правила сдачи \n",
    "\n",
    "1. Домашняя работа должна быть выполнена в ipynb-тетрадке.\n",
    "2. Сделанную тетрадку нужно отправить ассистенту (ссылка на контакты будет в вики).\n",
    "3. Задание выполняется индивидуально.\n",
    "4. Все вычисления должны быть снабжены пояснениями!\n",
    "5. Дедлайн – 10 июня в 10.00.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
